{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7222412,
          "sourceType": "datasetVersion",
          "datasetId": 4180521
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_haTnXqIncfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "k96R9oYNnQO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:07.168058Z",
          "iopub.execute_input": "2023-12-22T08:06:07.168816Z",
          "iopub.status.idle": "2023-12-22T08:06:07.175243Z",
          "shell.execute_reply.started": "2023-12-22T08:06:07.168772Z",
          "shell.execute_reply": "2023-12-22T08:06:07.173706Z"
        },
        "trusted": true,
        "id": "fLMDf1g2nQO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "8sVj0xFNnQO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    sequence_length = 1024\n",
        "    vocab_size = 10000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:09.431605Z",
          "iopub.execute_input": "2023-12-22T08:06:09.432886Z",
          "iopub.status.idle": "2023-12-22T08:06:09.437735Z",
          "shell.execute_reply.started": "2023-12-22T08:06:09.432825Z",
          "shell.execute_reply": "2023-12-22T08:06:09.436844Z"
        },
        "trusted": true,
        "id": "v4QCIU4QnQO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data"
      ],
      "metadata": {
        "id": "1bauUBZOnQO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df = pd.read_csv(\"/kaggle/input/fake-news-detection/true.csv\")\n",
        "negative_df[\"fake\"] = 0.0\n",
        "positive_df = pd.read_csv(\"/kaggle/input/fake-news-detection/fake.csv\")\n",
        "positive_df[\"fake\"] = 1.0\n",
        "train_df = pd.concat([negative_df, positive_df])\n",
        "train_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:11.401432Z",
          "iopub.execute_input": "2023-12-22T08:06:11.403004Z",
          "iopub.status.idle": "2023-12-22T08:06:14.681298Z",
          "shell.execute_reply.started": "2023-12-22T08:06:11.402924Z",
          "shell.execute_reply": "2023-12-22T08:06:14.679546Z"
        },
        "trusted": true,
        "id": "a4jvuiopnQO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Data"
      ],
      "metadata": {
        "id": "gLaKeQ4znQO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.fake.value_counts().plot(kind=\"bar\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:07:00.312273Z",
          "iopub.execute_input": "2023-12-22T08:07:00.313221Z",
          "iopub.status.idle": "2023-12-22T08:07:00.573678Z",
          "shell.execute_reply.started": "2023-12-22T08:07:00.313177Z",
          "shell.execute_reply": "2023-12-22T08:07:00.572356Z"
        },
        "trusted": true,
        "id": "XLH_1sm2nQO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"title_length\"] = train_df[\"title\"].apply(lambda title: len(title.split(\" \")))\n",
        "train_df[\"text_length\"] = train_df[\"text\"].apply(lambda text: len(text.split(\" \")))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:19.82659Z",
          "iopub.execute_input": "2023-12-22T08:06:19.82819Z",
          "iopub.status.idle": "2023-12-22T08:06:21.202679Z",
          "shell.execute_reply.started": "2023-12-22T08:06:19.828111Z",
          "shell.execute_reply": "2023-12-22T08:06:21.20136Z"
        },
        "trusted": true,
        "id": "1CsvS0DMnQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[[\"title_length\", \"text_length\"]].describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:23.93532Z",
          "iopub.execute_input": "2023-12-22T08:06:23.935916Z",
          "iopub.status.idle": "2023-12-22T08:06:23.975964Z",
          "shell.execute_reply.started": "2023-12-22T08:06:23.935864Z",
          "shell.execute_reply": "2023-12-22T08:06:23.974477Z"
        },
        "trusted": true,
        "id": "omUvVoDunQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Visualize the distribution of values of title length and text length."
      ],
      "metadata": {
        "id": "Jllwe3fRnQPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"title_length\"].plot(kind=\"hist\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:26.06523Z",
          "iopub.execute_input": "2023-12-22T08:06:26.065847Z",
          "iopub.status.idle": "2023-12-22T08:06:26.38801Z",
          "shell.execute_reply.started": "2023-12-22T08:06:26.06576Z",
          "shell.execute_reply": "2023-12-22T08:06:26.386573Z"
        },
        "trusted": true,
        "id": "NRUBAdmHnQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"text_length\"].plot(kind=\"hist\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:06:28.769544Z",
          "iopub.execute_input": "2023-12-22T08:06:28.770385Z",
          "iopub.status.idle": "2023-12-22T08:06:29.114795Z",
          "shell.execute_reply.started": "2023-12-22T08:06:28.770332Z",
          "shell.execute_reply": "2023-12-22T08:06:29.113505Z"
        },
        "trusted": true,
        "id": "5CxL2f7TnQPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tensorflow dataset"
      ],
      "metadata": {
        "id": "MyiWfBFWnQPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data = train_test_split(train_df, test_size=0.2, stratify=train_df[\"fake\"], random_state=42)\n",
        "train_data.shape, valid_data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:07:05.753919Z",
          "iopub.execute_input": "2023-12-22T08:07:05.754382Z",
          "iopub.status.idle": "2023-12-22T08:07:06.685636Z",
          "shell.execute_reply.started": "2023-12-22T08:07:05.754349Z",
          "shell.execute_reply": "2023-12-22T08:07:06.684113Z"
        },
        "trusted": true,
        "id": "Rd8f5WpunQPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataframe, shuffle=True):\n",
        "    # Create a TensorFlow dataset from the text and fake columns of the dataframe\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dataframe[\"text\"], dataframe[\"fake\"]))\n",
        "    if shuffle:\n",
        "         # Shuffle the dataset if the shuffle parameter is True\n",
        "        dataset = dataset.shuffle(1024, reshuffle_each_iteration=True)\n",
        "    # Batch the dataset into smaller batches of size 256\n",
        "    dataset = dataset.batch(256).cache().prefetch(tf.data.AUTOTUNE)\n",
        "    # Prefetch the next batch of data to further optimize training\n",
        "    return dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:07:08.921153Z",
          "iopub.execute_input": "2023-12-22T08:07:08.921605Z",
          "iopub.status.idle": "2023-12-22T08:07:09.243693Z",
          "shell.execute_reply.started": "2023-12-22T08:07:08.921566Z",
          "shell.execute_reply": "2023-12-22T08:07:09.242496Z"
        },
        "trusted": true,
        "id": "e-L29GIfnQPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tensorflow training dataset and validation dataset."
      ],
      "metadata": {
        "id": "RVFHqBJwnQPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = create_dataset(train_data)\n",
        "valid_ds = create_dataset(valid_data, shuffle=False)"
      ],
      "metadata": {
        "id": "8P9SCRQRnQPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[](http://)"
      ],
      "metadata": {
        "id": "nresY3sInQPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the LSTM Model"
      ],
      "metadata": {
        "id": "eKrKp51znQPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TextVectorization layer with specified parameters\n",
        "vectorizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=CFG.vocab_size,\n",
        "    output_sequence_length=CFG.sequence_length,\n",
        "    pad_to_max_tokens=True\n",
        ")\n",
        "# Adapt the TextVectorization layer to the training data\n",
        "vectorizer.adapt(train_df[\"text\"], batch_size=1024)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:07:13.240159Z",
          "iopub.execute_input": "2023-12-22T08:07:13.240658Z",
          "iopub.status.idle": "2023-12-22T08:07:24.100528Z",
          "shell.execute_reply.started": "2023-12-22T08:07:13.240622Z",
          "shell.execute_reply": "2023-12-22T08:07:24.099502Z"
        },
        "trusted": true,
        "id": "K8CkXr5hnQPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    vectorizer,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=CFG.vocab_size,\n",
        "        output_dim=64,\n",
        "        input_length=CFG.sequence_length,\n",
        "        mask_zero=True\n",
        "    ),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.AUC(name=\"auc\")\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T08:11:30.070393Z",
          "iopub.execute_input": "2023-12-22T08:11:30.07094Z",
          "iopub.status.idle": "2023-12-22T08:11:35.052976Z",
          "shell.execute_reply.started": "2023-12-22T08:11:30.070898Z",
          "shell.execute_reply": "2023-12-22T08:11:35.051384Z"
        },
        "trusted": true,
        "id": "AsYtImYPnQPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"model.tf\"\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            file_path,\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max'\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-22T15:49:07.900708Z",
          "iopub.execute_input": "2023-12-22T15:49:07.901498Z",
          "iopub.status.idle": "2023-12-22T15:49:08.23136Z",
          "shell.execute_reply.started": "2023-12-22T15:49:07.901466Z",
          "shell.execute_reply": "2023-12-22T15:49:08.230208Z"
        },
        "trusted": true,
        "id": "JJtjfqhgnQPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot learning curve"
      ],
      "metadata": {
        "id": "vcAJgvZvnQPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(history):\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.plot(history.history['auc'])\n",
        "  plt.plot(history.history['val_auc'])\n",
        "  plt.title('AUC')\n",
        "  plt.ylabel('AUC')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "  plt.show()\n",
        "plot_learning_curve(history)"
      ],
      "metadata": {
        "id": "Tw1it-t6nQPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}